
import sys
import os
import torch
import soundfile as sf
import re
from datetime import datetime
from qwen_tts import Qwen3TTSModel

# -----------------------------------------------------------------------------
# [ì´ˆê¸° ì„¤ì •] GPU ë° FlashAttention ì„¤ì •
# -----------------------------------------------------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
dtype = torch.bfloat16 if device == "cuda" else torch.float32
attn_impl = "eager"

if device == "cuda":
    try:
        import flash_attn
        attn_impl = "flash_attention_2"
    except ImportError:
        print("âš ï¸ FlashAttentionì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ 'eager' ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")

# -----------------------------------------------------------------------------
# [ëª¨ë¸ ê²½ë¡œ ì„¤ì •]
# -----------------------------------------------------------------------------
MODELS = {
    "custom": "/mnt/c/Users/csj76/models/Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice",
    "design": "/mnt/c/Users/csj76/models/Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign",
    "clone": "/mnt/c/Users/csj76/models/Qwen/Qwen3-TTS-12Hz-1.7B-Base"
}

def load_model(path, model_name_for_log):
    print(f"\n[{model_name_for_log}] ëª¨ë¸ ë¡œë”© ì¤‘... ({path})")
    return Qwen3TTSModel.from_pretrained(
        path,
        device_map="auto",
        dtype=dtype,
        attn_implementation=attn_impl
    )

def get_output_filename(type_str, identifier):
    """
    íŒŒì¼ëª… ìƒì„± ê·œì¹™: output-<type>-<identifier>-<YYMMDDHHMM>.wav
    - identifier: ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ìëŠ” '_'ë¡œ ì¹˜í™˜
    - timestamp: í˜„ì¬ ì‹œê°„
    """
    # 1. Identifier ì •ì œ (íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ë° ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì¹˜í™˜)
    # í•œê¸€, ì˜ë¬¸, ìˆ«ì, ì–¸ë”ë°”, í•˜ì´í”ˆì„ ì œì™¸í•œ ëª¨ë“  ë¬¸ìë¥¼ '_'ë¡œ ë³€ê²½
    clean_identifier = re.sub(r'[^ê°€-í£a-zA-Z0-9_\-]', '_', str(identifier))
    # ì—°ì†ëœ ì–¸ë”ë°”ëŠ” í•˜ë‚˜ë¡œ ì¤„ì„
    clean_identifier = re.sub(r'_+', '_', clean_identifier)
    
    # 2. ë‚ ì§œ í¬ë§· (YYMMDDHHMM)
    timestamp = datetime.now().strftime("%y%m%d%H%M")
    
    return f"output-{type_str}-{clean_identifier}-{timestamp}.wav"

# -----------------------------------------------------------------------------
# [ê¸°ëŠ¥ êµ¬í˜„]
# -----------------------------------------------------------------------------

def run_custom_voice(text, speaker):
    """
    1. CustomVoice: í”„ë¦¬ì…‹ í™”ì ì‚¬ìš©
    """
    model = load_model(MODELS["custom"], "CustomVoice")
    
    # ê¸°ë³¸ instruct (í•„ìš”í•˜ë‹¤ë©´ ìƒìˆ˜ë¡œ ë¹¼ê±°ë‚˜ ì¸ìë¡œ ë°›ì„ ìˆ˜ ìˆìŒ)
    default_instruct = "ì°¨ë¶„í•˜ê³  ì „ë¬¸ì ì¸ ë‰´ìŠ¤ ì•µì»¤ í†¤ìœ¼ë¡œ(Speak in a calm and professional news anchor tone)"
    
    print(f"ğŸ™ï¸ ìƒì„± ì¤‘: '{text}' (Speaker: {speaker})")
    
    wavs, sr = model.generate_custom_voice(
        text=text,
        language="Korean",
        speaker=speaker,
        instruct=default_instruct
    )
    
    # output-custom_voice-<Speaker>-<Date>.wav
    output_filename = get_output_filename("custom_voice", speaker)
    
    sf.write(output_filename, wavs[0], sr)
    print(f"âœ… ì™„ë£Œ: {output_filename}")

def run_voice_design(text, instruct):
    """
    2. VoiceDesign: ëª©ì†Œë¦¬ ë¬˜ì‚¬ ì‚¬ìš©
    """
    model = load_model(MODELS["design"], "VoiceDesign")
    
    print(f"ğŸ™ï¸ ìƒì„± ì¤‘: '{text}'")
    print(f"âœ¨ ëª©ì†Œë¦¬ ë¬˜ì‚¬: {instruct}")
    
    wavs, sr = model.generate_voice_design(
        text=text,
        language="Korean",
        instruct=instruct
    )
    
    # output-voice_design-<Instructì•10ê¸€ì>-<Date>.wav
    # instructê°€ ê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì• 10ê¸€ìë§Œ ì‚¬ìš©
    short_instruct = instruct[:10]
    output_filename = get_output_filename("voice_design", short_instruct)
    
    sf.write(output_filename, wavs[0], sr)
    print(f"âœ… ì™„ë£Œ: {output_filename}")

def run_voice_clone(text, ref_audio_path, ref_text=None):
    """
    3. VoiceClone: ëª©ì†Œë¦¬ ë³µì œ
    """
    model = load_model(MODELS["clone"], "VoiceClone")
    
    # ref_textê°€ ì œê³µë˜ì§€ ì•Šì•˜ì„ ê²½ìš° (CLI ëª¨ë“œ ë“±ì—ì„œ)
    if not ref_text:
        print("\nâ„¹ï¸  ì°¸ì¡° ì˜¤ë””ì˜¤ì˜ í…ìŠ¤íŠ¸(Transcript)ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        ref_text = input("   ë³µì œ í’ˆì§ˆì„ ìœ„í•´ ì°¸ì¡° ì˜¤ë””ì˜¤ì˜ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ëª¨ë¥´ë©´ Enter): ").strip()
        if not ref_text:
            print("âš ï¸  Warning: ì°¸ì¡° í…ìŠ¤íŠ¸ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤. í’ˆì§ˆì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # í…ìŠ¤íŠ¸ê°€ ê¼­ í•„ìš”í•˜ë‹¤ë©´ ì„ì˜ì˜ ê°’ì´ë‚˜ ì—ëŸ¬ ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            # ì—¬ê¸°ì„œëŠ” ë¹ˆ ë¬¸ìì—´ì´ë‚˜ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ì‹œë„
            ref_text = "The quick brown fox jumps over the lazy dog." 
    
    print(f"ğŸ™ï¸ ìƒì„± ì¤‘: '{text}'")
    print(f"ğŸ”Š ì°¸ì¡° íŒŒì¼: {ref_audio_path}")
    
    wavs, sr = model.generate_voice_clone(
        text=text,
        language="Korean",
        ref_audio=ref_audio_path,
        ref_text=ref_text
    )
    
    # output-voice_clone-<RefFileName>-<Date>.wav
    # ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì ì œì™¸)
    base_name = os.path.basename(ref_audio_path)
    file_name_without_ext = os.path.splitext(base_name)[0]
    
    output_filename = get_output_filename("voice_clone", file_name_without_ext)

    sf.write(output_filename, wavs[0], sr)
    print(f"âœ… ì™„ë£Œ: {output_filename}")

# -----------------------------------------------------------------------------
# [ë©”ì¸ ë¡œì§]
# -----------------------------------------------------------------------------

def print_help():
    print("""
[ì‚¬ìš©ë²•] python tts.py [ëª¨ë“œë²ˆí˜¸] [ì¸ì...]

1. Custom Voice (í”„ë¦¬ì…‹)
   ì‚¬ìš©ë²•: python tts.py 1 "ë³€í™˜í•  í…ìŠ¤íŠ¸" [í”„ë¦¬ì…‹ì´ë¦„ (ê¸°ë³¸ê°’: Sohee)]
   ì˜ˆì‹œ:   python tts.py 1 "ì•ˆë…•í•˜ì„¸ìš”" Aiden

2. Voice Design (ëª©ì†Œë¦¬ ë¬˜ì‚¬)
   ì‚¬ìš©ë²•: python tts.py 2 "ë³€í™˜í•  í…ìŠ¤íŠ¸" "ëª©ì†Œë¦¬ ë¬˜ì‚¬"
   ì˜ˆì‹œ:   python tts.py 2 "ì•ˆë…•í•˜ì„¸ìš”" "ê·€ì—¬ìš´ í•œêµ­ì¸ ì—¬ìì•„ì´ ëª©ì†Œë¦¬"

3. Voice Clone (ëª©ì†Œë¦¬ ë³µì œ)
   ì‚¬ìš©ë²•: python tts.py 3 "ë³€í™˜í•  í…ìŠ¤íŠ¸" "ëª©ì†Œë¦¬ íŒŒì¼ ê²½ë¡œ"
   ì˜ˆì‹œ:   python tts.py 3 "ì•ˆë…•í•˜ì„¸ìš”" "./my_voice.wav"

* ì¸ì ì—†ì´ ì‹¤í–‰ ì‹œ ëŒ€í™”í˜• ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
""")

def main():
    args = sys.argv[1:]
    
    # 1. ì¸ìê°€ ì—†ëŠ” ê²½ìš° -> ëŒ€í™”í˜• ëª¨ë“œ
    if len(args) == 0:
        print("\n=== Qwen3 TTS ëŒ€í™”í˜• ëª¨ë“œ ===")
        print("1. Custom Voice (í”„ë¦¬ì…‹ ì„ íƒ)")
        print("2. Voice Design (ëª©ì†Œë¦¬ ë¬˜ì‚¬)")
        print("3. Voice Clone  (ëª©ì†Œë¦¬ ë³µì œ)")
        
        mode = input("\nì›í•˜ëŠ” ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (1/2/3): ").strip()
        
        if mode == "1":
            t = input("ë³€í™˜í•  í…ìŠ¤íŠ¸: ").strip()
            s = input("ì›í•˜ëŠ” í”„ë¦¬ì…‹ (ê¸°ë³¸ê°’ Sohee): ").strip()
            if not s: s = "Sohee"
            run_custom_voice(t, s)
            
        elif mode == "2":
            t = input("ë³€í™˜í•  í…ìŠ¤íŠ¸: ").strip()
            i = input("ì›í•˜ëŠ” ëª©ì†Œë¦¬ ë¬˜ì‚¬: ").strip()
            run_voice_design(t, i)
            
        elif mode == "3":
            t = input("ë³€í™˜í•  í…ìŠ¤íŠ¸: ").strip()
            p = input("ì°¸ì¡° ì˜¤ë””ì˜¤ ê²½ë¡œ: ").strip()
            # ëŒ€í™”í˜•ì—ì„œëŠ” ëª…ì‹œì ìœ¼ë¡œ ë°›ìŒ
            r = input("ì°¸ì¡° ì˜¤ë””ì˜¤ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©: ").strip()
            run_voice_clone(t, p, r)
            
        else:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
            
    # 2. ì¸ìê°€ ìˆëŠ” ê²½ìš° -> CLI ëª¨ë“œ
    else:
        mode = args[0]
        
        if mode == "1":
            # python tts.py 1 "text" "speaker"
            if len(args) < 2:
                print("âŒ í…ìŠ¤íŠ¸ ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                print_help()
                return
            
            text = args[1]
            speaker = args[2] if len(args) > 2 else "Sohee"
            run_custom_voice(text, speaker)
            
        elif mode == "2":
            # python tts.py 2 "text" "instruct"
            if len(args) < 3:
                print("âŒ í…ìŠ¤íŠ¸ì™€ ë¬˜ì‚¬ ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                print_help()
                return
                
            text = args[1]
            instruct = args[2]
            run_voice_design(text, instruct)
            
        elif mode == "3":
            # python tts.py 3 "text" "path"
            if len(args) < 3:
                print("âŒ í…ìŠ¤íŠ¸ì™€ íŒŒì¼ ê²½ë¡œ ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                print_help()
                return
                
            text = args[1]
            path = args[2]
            # CLI ëª¨ë“œì—ì„œëŠ” ref_textë¥¼ ì¸ìë¡œ ë°›ì§€ ì•Šê¸°ë¡œ í–ˆìœ¼ë¯€ë¡œ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬(None ì „ë‹¬)
            run_voice_clone(text, path, ref_text=None)
            
        else:
            print_help()

if __name__ == "__main__":
    main()
